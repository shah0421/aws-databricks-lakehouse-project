{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb6b140b-8802-456f-ae26-077842c02414",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Stream Customers Data From Cloud Files to Delta Lake Using Autoloader\n",
    "1. Read files from cloud storage using DataStreamReader API\n",
    "2. Transform the dataframe to add the following columns\n",
    "    - file path: Cloud file path\n",
    "    - ingest data: Current Timestamp\n",
    "3. Write the transformed data stream to Delta Lake Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b884a4c-b329-4b01-b953-97313da04cda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Spark Structured Streaming has some limitations when processing large amount of data. \n",
    "  - Inefficient File Listing (It repeatedly scans entire directory to find new files. It can be slow and expensive when dealing with millions of files).\n",
    "  - Scalability Issues (Duplicate file detection is acheived by storing the list of files already processed in a in-momory map on the driver. It does not scale well).\n",
    "  - Schema Evolution Problems (Users must manually define the schema before the steaming starts. if any new column starts coming later, it may cause data loss or require manual intervension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5095543d-52cc-4453-9e7d-a2e295df0e57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Auto Loader\n",
    "  - Efficient File Detection using Cloud Services (Efficiently uses AWS Event Notifications to track new files)\n",
    "  - Scalability Improvements (It replaces in-memory tracking with cloud storage)\n",
    "  - Schema Evolution & Resiliency (Supports automatic schema inference from sample files.Also supports automatic shema evolution by automatically adding new columns or rescueing unexpected data in a separate rescue data column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1441496d-0c24-47a0-9067-4e15c326a627",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Read files from cloud storage using DataStreamReader API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a2250a6-88a4-4375-83f2-5b6d18e39669",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "customers_df = (\n",
    "    spark.readStream\n",
    "    .format(\"cloudFiles\")\n",
    "    .option(\"cloudFiles.format\", \"json\")\n",
    "    .option(\"cloudFiles.schemaLocation\", \"/Volumes/gizmobox/landing/operational_data/Customers_autoloader/_schema\")\n",
    "    .option(\"cloudFiles.inferColumnTypes\", \"true\")\n",
    "    .option(\"cloudFiles.schemaHints\", \"date_of_birth Date, member_since Date, created_timestamp TIMESTAMP\")\n",
    "    .load(\"/Volumes/gizmobox/landing/operational_data/Customers_autoloader/\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5bf5cc3-0756-4c9a-9cc8-848a9f2916f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Transform the dataframe to add the following columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a2f3c7e-4599-4462-8eea-a370e0b47dc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp, col\n",
    "customer_transformed_df = (\n",
    "    customers_df\n",
    "    .withColumn(\"file_path\", col(\"_metadata.file_path\"))\n",
    "    .withColumn(\"ingestion_date\", current_timestamp())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12a114eb-20fc-4e49-8cbd-9f93fd420165",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. Write the transformed data stream to Delta Lake Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73ca1d4a-e02f-4ced-9063-c83428f357d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## uncomment only when you want to start streaming. please make sure to terminate it after use.\n",
    "# streaming_query = (\n",
    "#         customer_transformed_df.writeStream\n",
    "#             .format(\"delta\")\n",
    "#             .option(\"checkpointLocation\", \"/Volumes/gizmobox/landing/operational_data/Customers_autoloader/_checkpoint_stream\")\n",
    "#             .toTable(\"gizmobox.bronze.customers_autoloader\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b51517b-2ada-4113-9686-f854d8954751",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1765062353091}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from gizmobox.bronze.customers_autoloader;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "854c6495-18c3-42ed-9703-7e1d56fc068a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "streaming_query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d32830f0-bcd6-4734-89ef-905bea6f61e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3362787942243619,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "02. Ingest Customers Auto Loader",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
