# ğŸ“˜ ETL Lakehouse Workflow Project 
## Medallion Architecture + Terraform Infrastructure

This project demonstrates an end-to-end **AWS Databricks Lakehouse** implementation, including:

- Automated infrastructure provisioning using **Terraform**
- Ingesting data from **multiple sources & formats**
- Applying the **Medallion Architecture** (Bronze â†’ Silver â†’ Gold)
- Building analytics-ready **Gold Layer** tables for BI & ML
- Integration with **S3, IAM, Secrets Manager, JDBC**
- Using **Unity Catalog** for secure governance

All AWS resources required for Databricks + S3 access are provisioned using Terraform following IAM and security best practices.

---

# ğŸ— ETL Architecture Overview

This project implements the **Medallion Architecture**:

```pgsql

Landing (S3 Raw Data)
â†“
Bronze (Ingested Raw Tables)
â†“
Silver (Cleaned / Conformed)
â†“
Gold (BI + ML Ready Models)
```

---

# Data Structure

<p align="center">
  <img src="./../images/data_diagram.png" width="600">
</p>

---


# ğŸ“¦ Data Sources

- **Customers** â†’ JSON files  
- **Addresses** â†’ CSV files  
- **Memberships** â†’ Image files (`binaryFile` format)  
- **Orders** â†’ CSV  
- **Payments** â†’ Monthly CSV extracts  
- **Refunds** â†’ PostgreSQL table via JDBC  

---

# ğŸŸ¨ Final Gold Outputs

### **customer_address**
Single record per customer with flattened address information.

### **order_monthly_summary**
Monthly customer order aggregated metrics:
- total orders  
- total items  
- total amount spent  

---